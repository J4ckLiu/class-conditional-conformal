{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc1280f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os, time, copy\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision.models import resnet50\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from cifar_utils import get_model, get_data, show_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0709702",
   "metadata": {},
   "source": [
    "The easiest way to access a GPU for model training is to request one using srun or sbatch and run `python cifar_utils.py` (make sure to update the config in that file as appropriate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73ea3e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "config = {\n",
    "        'num_classes' : 100,\n",
    "        'batch_size' : 128,\n",
    "        'lr' : 0.0001,\n",
    "        'feature_extract' : False, # If False, fine tune all layers. If True, fine tune last layer only\n",
    "        'num_epochs' : 30,\n",
    "        'device' : 'cpu',\n",
    "        'frac_val' : 0.5, # CHANGED FROM 0.3\n",
    "        'model_filename' : 'best-cifar100-model-fracval=0.7', # CHANGED FROM no suffix\n",
    "        'num_workers' : 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7d0910f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.0.conv3.weight\n",
      "\t layer1.0.bn3.weight\n",
      "\t layer1.0.bn3.bias\n",
      "\t layer1.0.downsample.0.weight\n",
      "\t layer1.0.downsample.1.weight\n",
      "\t layer1.0.downsample.1.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer1.1.conv3.weight\n",
      "\t layer1.1.bn3.weight\n",
      "\t layer1.1.bn3.bias\n",
      "\t layer1.2.conv1.weight\n",
      "\t layer1.2.bn1.weight\n",
      "\t layer1.2.bn1.bias\n",
      "\t layer1.2.conv2.weight\n",
      "\t layer1.2.bn2.weight\n",
      "\t layer1.2.bn2.bias\n",
      "\t layer1.2.conv3.weight\n",
      "\t layer1.2.bn3.weight\n",
      "\t layer1.2.bn3.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.conv3.weight\n",
      "\t layer2.0.bn3.weight\n",
      "\t layer2.0.bn3.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer2.1.conv3.weight\n",
      "\t layer2.1.bn3.weight\n",
      "\t layer2.1.bn3.bias\n",
      "\t layer2.2.conv1.weight\n",
      "\t layer2.2.bn1.weight\n",
      "\t layer2.2.bn1.bias\n",
      "\t layer2.2.conv2.weight\n",
      "\t layer2.2.bn2.weight\n",
      "\t layer2.2.bn2.bias\n",
      "\t layer2.2.conv3.weight\n",
      "\t layer2.2.bn3.weight\n",
      "\t layer2.2.bn3.bias\n",
      "\t layer2.3.conv1.weight\n",
      "\t layer2.3.bn1.weight\n",
      "\t layer2.3.bn1.bias\n",
      "\t layer2.3.conv2.weight\n",
      "\t layer2.3.bn2.weight\n",
      "\t layer2.3.bn2.bias\n",
      "\t layer2.3.conv3.weight\n",
      "\t layer2.3.bn3.weight\n",
      "\t layer2.3.bn3.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.conv3.weight\n",
      "\t layer3.0.bn3.weight\n",
      "\t layer3.0.bn3.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer3.1.conv3.weight\n",
      "\t layer3.1.bn3.weight\n",
      "\t layer3.1.bn3.bias\n",
      "\t layer3.2.conv1.weight\n",
      "\t layer3.2.bn1.weight\n",
      "\t layer3.2.bn1.bias\n",
      "\t layer3.2.conv2.weight\n",
      "\t layer3.2.bn2.weight\n",
      "\t layer3.2.bn2.bias\n",
      "\t layer3.2.conv3.weight\n",
      "\t layer3.2.bn3.weight\n",
      "\t layer3.2.bn3.bias\n",
      "\t layer3.3.conv1.weight\n",
      "\t layer3.3.bn1.weight\n",
      "\t layer3.3.bn1.bias\n",
      "\t layer3.3.conv2.weight\n",
      "\t layer3.3.bn2.weight\n",
      "\t layer3.3.bn2.bias\n",
      "\t layer3.3.conv3.weight\n",
      "\t layer3.3.bn3.weight\n",
      "\t layer3.3.bn3.bias\n",
      "\t layer3.4.conv1.weight\n",
      "\t layer3.4.bn1.weight\n",
      "\t layer3.4.bn1.bias\n",
      "\t layer3.4.conv2.weight\n",
      "\t layer3.4.bn2.weight\n",
      "\t layer3.4.bn2.bias\n",
      "\t layer3.4.conv3.weight\n",
      "\t layer3.4.bn3.weight\n",
      "\t layer3.4.bn3.bias\n",
      "\t layer3.5.conv1.weight\n",
      "\t layer3.5.bn1.weight\n",
      "\t layer3.5.bn1.bias\n",
      "\t layer3.5.conv2.weight\n",
      "\t layer3.5.bn2.weight\n",
      "\t layer3.5.bn2.bias\n",
      "\t layer3.5.conv3.weight\n",
      "\t layer3.5.bn3.weight\n",
      "\t layer3.5.bn3.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.conv3.weight\n",
      "\t layer4.0.bn3.weight\n",
      "\t layer4.0.bn3.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t layer4.1.conv3.weight\n",
      "\t layer4.1.bn3.weight\n",
      "\t layer4.1.bn3.bias\n",
      "\t layer4.2.conv1.weight\n",
      "\t layer4.2.bn1.weight\n",
      "\t layer4.2.bn1.bias\n",
      "\t layer4.2.conv2.weight\n",
      "\t layer4.2.bn2.weight\n",
      "\t layer4.2.bn2.bias\n",
      "\t layer4.2.conv3.weight\n",
      "\t layer4.2.bn3.weight\n",
      "\t layer4.2.bn3.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 3.7631 Acc: 0.1689\n",
      "val Loss: 2.6022 Acc: 0.3606\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 2.0157 Acc: 0.4753\n",
      "val Loss: 1.8349 Acc: 0.5079\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.2808 Acc: 0.6487\n",
      "val Loss: 1.6775 Acc: 0.5454\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.8410 Acc: 0.7673\n",
      "val Loss: 1.6588 Acc: 0.5647\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.5408 Acc: 0.8571\n",
      "val Loss: 1.6504 Acc: 0.5784\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.3501 Acc: 0.9127\n",
      "val Loss: 1.7247 Acc: 0.5827\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.2378 Acc: 0.9456\n",
      "val Loss: 1.7234 Acc: 0.5889\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.1623 Acc: 0.9646\n",
      "val Loss: 1.7923 Acc: 0.5907\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.1198 Acc: 0.9744\n",
      "val Loss: 1.8636 Acc: 0.5910\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.1034 Acc: 0.9778\n",
      "val Loss: 1.9842 Acc: 0.5821\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.0949 Acc: 0.9782\n",
      "val Loss: 1.9945 Acc: 0.5859\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.1030 Acc: 0.9759\n",
      "val Loss: 2.0277 Acc: 0.5912\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.0888 Acc: 0.9782\n",
      "val Loss: 2.1023 Acc: 0.5889\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.1023 Acc: 0.9738\n",
      "val Loss: 2.0661 Acc: 0.5906\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.0824 Acc: 0.9792\n",
      "val Loss: 2.1193 Acc: 0.5921\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.0715 Acc: 0.9810\n",
      "val Loss: 2.0828 Acc: 0.5881\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.0603 Acc: 0.9841\n",
      "val Loss: 2.0802 Acc: 0.5953\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.0534 Acc: 0.9858\n",
      "val Loss: 2.2534 Acc: 0.5940\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.0493 Acc: 0.9869\n",
      "val Loss: 2.2264 Acc: 0.5930\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.0535 Acc: 0.9854\n",
      "val Loss: 2.3266 Acc: 0.5909\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.0598 Acc: 0.9835\n",
      "val Loss: 2.2506 Acc: 0.5923\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.0443 Acc: 0.9875\n",
      "val Loss: 2.4576 Acc: 0.5931\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.0379 Acc: 0.9899\n",
      "val Loss: 2.3325 Acc: 0.5998\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.0473 Acc: 0.9868\n",
      "val Loss: 2.5001 Acc: 0.5946\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.0418 Acc: 0.9887\n",
      "val Loss: 2.4391 Acc: 0.5938\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.0419 Acc: 0.9888\n",
      "val Loss: 2.3594 Acc: 0.5964\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.0363 Acc: 0.9900\n",
      "val Loss: 2.4542 Acc: 0.5992\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.0355 Acc: 0.9899\n",
      "val Loss: 2.5777 Acc: 0.5904\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.0411 Acc: 0.9882\n",
      "val Loss: 2.3777 Acc: 0.5949\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.0383 Acc: 0.9890\n",
      "val Loss: 2.4047 Acc: 0.5958\n",
      "\n",
      "Training complete in 49m 4s\n",
      "Best val Acc: 0.599767\n"
     ]
    }
   ],
   "source": [
    "model = get_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b942258",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "=== With frac_val = 0.7 === \n",
    "Epoch 29/29\n",
    "----------\n",
    "train Loss: 0.0295 Acc: 0.9938\n",
    "val Loss: 2.5458 Acc: 0.5470\n",
    "\n",
    "Training complete in 4m 43s\n",
    "Best val Acc: 0.546976\n",
    "'''\n",
    "\n",
    "'''\n",
    "=== With frac_val = 0.5 ===  <-- THIS IS WHAT WE USE\n",
    "Epoch 29/29\n",
    "----------\n",
    "train Loss: 0.0315 Acc: 0.9913\n",
    "val Loss: 2.3326 Acc: 0.5974\n",
    "\n",
    "Training complete in 6m 44s\n",
    "Best val Acc: 0.597367\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "=== With frac_val = 0.3 === \n",
    "Epoch 0/0\n",
    "----------\n",
    "train Loss: 3.3722 Acc: 0.2335\n",
    "val Loss: 2.2128 Acc: 0.4491\n",
    "\n",
    "Training complete in 3m 27s\n",
    "Best val Acc: 0.449056\n",
    "\n",
    "\n",
    "Epoch 29/29\n",
    "----------\n",
    "train Loss: 0.0373 Acc: 0.9889\n",
    "val Loss: 2.4569 Acc: 0.6305\n",
    "\n",
    "Training complete in 64m 27s\n",
    "Best val Acc: 0.630556\n",
    "'''\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a976e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_imgs = np.load('./.cache/' + config['model_filename'] + f'-valdata_frac={config[\"frac_val\"]}.npy')\n",
    "val_labels = np.load('./.cache/' + config['model_filename'] + f'-vallabels_frac={config[\"frac_val\"]}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d5c6e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img(val_imgs[np.random.choice(val_imgs.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa2d72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 39s, sys: 9min 22s, total: 15min 1s\n",
      "Wall time: 26.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Get softmax scores\n",
    "with torch.no_grad():\n",
    "    logits = model(torch.from_numpy(val_imgs))\n",
    "    \n",
    "softmax_scores = torch.nn.functional.softmax(logits,dim=1)\n",
    "softmax_scores = softmax_scores.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59ad2db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save softmax scores to ./.cache/best-cifar100-model-fracval=0.7-valsoftmax_frac=0.5.npy\n"
     ]
    }
   ],
   "source": [
    "# Save softmax scores\n",
    "pth = './.cache/' + config['model_filename'] + f'-valsoftmax_frac={config[\"frac_val\"]}.npy'\n",
    "\n",
    "np.save(pth, softmax_scores)\n",
    "print(f'Save softmax scores to {pth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114c1685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
