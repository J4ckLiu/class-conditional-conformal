{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "781b741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import torch\n",
    "\n",
    "from collections import Counter\n",
    "from gap_statistic import OptimalK\n",
    "from scipy import stats, cluster\n",
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "from utils.conformal_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee4d4d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_embedding(samples, q=[0.5, 0.6, 0.7, 0.8, 0.9]):\n",
    "    '''\n",
    "    Computes the q-quantiles of samples and returns the vector of quantiles\n",
    "    '''\n",
    "    return np.quantile(samples, q)\n",
    "\n",
    "def embed_all_classes(scores_all, labels, q=[0.5, 0.6, 0.7, 0.8, 0.9]):\n",
    "    '''\n",
    "    Input:\n",
    "        - scores_all: num_instances x num_classes array where \n",
    "        cal_class_scores[i,j] = score of class j for instance i\n",
    "        - labels: num_instances-length array of true class labels\n",
    "        \n",
    "    Output: num_classes x len(q) array where ith row is the embeddings of class i\n",
    "    '''\n",
    "    num_classes = scores_all.shape[1]\n",
    "    \n",
    "    embeddings = np.zeros((num_classes, len(q)))\n",
    "    for i in range(num_classes):\n",
    "        class_i_scores = scores_all[labels==i,i]\n",
    "        embeddings[i,:] = quantile_embedding(class_i_scores, q=q)\n",
    "    \n",
    "    return embeddings\n",
    "    \n",
    "\n",
    "def _clustered_conformal(totalcal_scores, totalcal_labels,\n",
    "                        alpha,\n",
    "                        n_clustering, num_clusters,\n",
    "                        val_scores=None, val_labels=None):\n",
    "    '''\n",
    "    Helper for clustered_conformal() that assumes clustering_frac\n",
    "    and num_clusters are given. See clustered_conformal() for documentation.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    num_classes = totalcal_scores.shape[1]\n",
    "    \n",
    "    # 0) Split data \n",
    "    scores1_all, labels1, scores2_all, labels2 = split_X_and_y(totalcal_scores_all, \n",
    "                                                               totalcal_labels, \n",
    "                                                               n_clustering, \n",
    "                                                               num_classes=num_classes, \n",
    "                                                               seed=0)\n",
    "    \n",
    "    # 1) Compute embedding for each class\n",
    "    embeddings = embed_all_classes(scores1_all, labels1, q=[0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "        \n",
    "    # 2) Cluster classes\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=0, n_init=10).fit(embeddings)\n",
    "    cluster_assignments = kmeans.labels_  \n",
    "    \n",
    "    # Print cluster sizes\n",
    "    print(f'Cluster sizes:', [x[1] for x in Counter(cluster_assignments).most_common()])\n",
    "    \n",
    "    # 3) Compute qhats for each cluster\n",
    "    cal_scores_all = scores2_all\n",
    "    cal_labels = labels2\n",
    "    qhats = compute_cluster_specific_qhats(cluster_assignments, \n",
    "               cal_scores_all, cal_labels, \n",
    "               alpha=alpha, \n",
    "               default_qhat=np.inf)\n",
    "    \n",
    "    # 4) [Optionally] Apply to val set. Evaluate class coverage gap and set size \n",
    "    if (val_scores is not None) and (val_labels is not None):\n",
    "        preds = create_cb_prediction_sets(val_scores_all, qhats)\n",
    "        class_specific_cov = compute_class_specific_coverage(val_labels, preds)\n",
    "\n",
    "        class_cov_gap = np.sum(np.abs(class_specific_cov - (1-alpha)))\n",
    "\n",
    "        curr_set_sizes = [len(x) for x in preds]\n",
    "        set_size_metrics = {'mean': np.mean(curr_set_sizes), '[.25, .5, .75, .9] quantiles': np.quantile(curr_set_sizes, [.25, .5, .75, .9])}\n",
    "        \n",
    "        return qhats, preds, class_cov_gap, set_size_metrics\n",
    "    else:\n",
    "        return qhats\n",
    "            \n",
    "\n",
    "\n",
    "def clustered_conformal(totalcal_scores, totalcal_labels,\n",
    "                        alpha,\n",
    "                        tune_parameters=True,\n",
    "                        n_clustering=None, num_clusters=None,\n",
    "                        val_scores=None, val_labels=None):\n",
    "    '''\n",
    "    Use totalcal_scores and total_labels to compute conformal quantiles for each\n",
    "    class using the clustered conformal procedure. Optionally evaluates \n",
    "    performance on val_scores and val_labels\n",
    "    \n",
    "    Inputs:\n",
    "         - totalcal_scores: num_instances x num_classes array where \n",
    "           cal_class_scores[i,j] = score of class j for instance i\n",
    "         - totalcal_labels: num_instances-length array of true class labels (0-indexed classes)\n",
    "         - alpha: number between 0 and 1 that determines coverage level.\n",
    "         Coverage level will be 1-alpha.\n",
    "         - tune_parameters: If True, ignore n_clustering and num_clusters\n",
    "         and tune the parameters using the elbow method. If False, use n_clustering\n",
    "         and num_clusters\n",
    "         - n_clustering: Number of points per class to use for clustering step. The remaining\n",
    "         points are used for the conformal calibration step.\n",
    "         - num_clusters: Number of clusters to group classes into\n",
    "         - val_scores: num_val_instances x num_classes array, or None. If not None, \n",
    "         the class coverage gap and average set sizes will be computed on val_scores\n",
    "         and val_labels.\n",
    "         - val_labels: num_val_instances-length array of true class labels, or None. \n",
    "         If not None, the class coverage gap and average set sizes will be computed \n",
    "         on val_scores and val_labels.\n",
    "         \n",
    "    Outputs:\n",
    "        - qhats: num_classes-length array where qhats[i] = conformal quantial estimate for class i\n",
    "        - [Optionally, if val_scores and val_labels are not None] \n",
    "            - val_preds: clustered conformal predictions on val_scores\n",
    "            - val_class_coverage_gap: Class coverage gap, compute on val_scores and val_labels\n",
    "            - val_set_size_metrics: Dict containing set size metrics, compute on val_scores and val_labels\n",
    "    '''\n",
    "    \n",
    "    num_classes = totalcal_scores.shape[1]\n",
    "    \n",
    "    if not tune_parameters:\n",
    "        assert n_clustering is not None and num_clusters is not None, \\\n",
    "        'When tune_parameters=False, clustering_frac and num_clusters must be defined'\n",
    "        \n",
    "        return _clustered_conformal(totalcal_scores, totalcal_labels,\n",
    "                                    alpha,\n",
    "                                    n_clustering, num_clusters,\n",
    "                                    val_scores=val_scores, val_labels=val_labels)\n",
    "    else:\n",
    "        \n",
    "        # List of possible amounts of data to use for clustering\n",
    "        # Try [.3, .5, .7, .9]-fractions of the rarest class in the calibration dataset\n",
    "        rarest_class_ct = Counter(totalcal_labels).most_common()[-1][1]\n",
    "        n_clustering_list = (np.array([.3, .5, .7, .9]) * rarest_class_ct).astype(np.int32)\n",
    "        \n",
    "        # List of possible numbers of clusters (1 through 10% of num_classes)\n",
    "        num_clusters_list = np.arange(1, np.ceil(.1 * num_classes)+1)\n",
    "        \n",
    "        best_k = [] # Best k for each n_clustering\n",
    "        best_k_score = [] # Inertia for each best k\n",
    "        \n",
    "        for n_clustering in n_clustering_list:\n",
    "            \n",
    "            # 0) Split data \n",
    "            scores1_all, labels1, scores2_all, labels2 = split_X_and_y(totalcal_scores_all, \n",
    "                                                               totalcal_labels, \n",
    "                                                               n_clustering, \n",
    "                                                               num_classes=num_classes, \n",
    "                                                               seed=0)\n",
    "    \n",
    "            # 1) Compute embedding for each class\n",
    "            embeddings = embed_all_classes(scores1_all, labels1, q=[0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "         \n",
    "            # 2) Do k-means with different k's\n",
    "            optimalK = OptimalK(parallel_backend='joblib')\n",
    "            maxgap_n_clusters = optimalK(embeddings, cluster_array=num_clusters_list)\n",
    "        \n",
    "            df = optimalK.gap_df\n",
    "            firstposdiff_n_clusters = int(df[df['diff'] > 0]['n_clusters'].tolist()[0])\n",
    "            gap_value = df[df['n_clusters'] == firstposdiff_n_clusters]['gap_value'].tolist()[0]\n",
    "\n",
    "            best_k.append(firstposdiff_n_clusters)\n",
    "            best_k_score.append(gap_value)\n",
    "            \n",
    "            \n",
    "        # Select n_clustering with lowest gap value at the elbow\n",
    "        min_idx = np.argmin(best_k_score)\n",
    "        best_n_clustering = n_clustering_list[min_idx]\n",
    "        best_num_clusters = best_k[min_idx]\n",
    "        print('Best n_clustering:', best_n_clustering)\n",
    "        print('Best num_clusters:', best_num_clusters)\n",
    "        \n",
    "        return _clustered_conformal(totalcal_scores, totalcal_labels,\n",
    "                                    alpha,\n",
    "                                    best_n_clustering, best_num_clusters,\n",
    "                                    val_scores=val_scores, val_labels=val_labels)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d663ee",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6dc2cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .1\n",
    "n_totalcal = 20 # Total number of calibration points (= # clustering examples + # conformal calibration examples)\n",
    "\n",
    "\n",
    "# Enron - BERT\n",
    "softmax_path = \"../class-conditional-conformal-datasets/notebooks/.cache/email_softmax_bert.npy\"\n",
    "labels_path = \"../class-conditional-conformal-datasets/notebooks/.cache/email_labels_bert.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b47275fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading softmax scores and labels...\n"
     ]
    }
   ],
   "source": [
    "## 1. Get data ============================\n",
    "print('Loading softmax scores and labels...')\n",
    "\n",
    "softmax_scores = np.load(softmax_path)\n",
    "labels = np.load(labels_path)\n",
    "\n",
    "num_classes = labels.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e18cd4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== score_function=softmax ======\n",
      "Computing conformal score...\n",
      "Splitting data...\n",
      "[n_clustering=3, num_clusters=1] Cluster sizes: [109]\n",
      "[n_clustering=3, num_clusters=2] Cluster sizes: [87, 22]\n",
      "[n_clustering=3, num_clusters=3] Cluster sizes: [74, 28, 7]\n",
      "[n_clustering=3, num_clusters=4] Cluster sizes: [62, 26, 17, 4]\n",
      "[n_clustering=3, num_clusters=5] Cluster sizes: [61, 26, 14, 6, 2]\n",
      "[n_clustering=3, num_clusters=6] Cluster sizes: [59, 22, 17, 5, 4, 2]\n",
      "[n_clustering=3, num_clusters=7] Cluster sizes: [59, 16, 13, 13, 4, 2, 2]\n",
      "[n_clustering=3, num_clusters=8] Cluster sizes: [59, 16, 13, 13, 3, 2, 2, 1]\n",
      "[n_clustering=3, num_clusters=9] Cluster sizes: [59, 16, 12, 11, 3, 3, 2, 2, 1]\n",
      "[n_clustering=3, num_clusters=10] Cluster sizes: [36, 23, 16, 12, 11, 3, 3, 2, 2, 1]\n",
      "[n_clustering=3, num_clusters=11] Cluster sizes: [31, 28, 16, 11, 8, 4, 3, 3, 2, 2, 1]\n",
      "[n_clustering=3, num_clusters=12] Cluster sizes: [36, 23, 15, 12, 7, 3, 3, 3, 2, 2, 2, 1]\n",
      "[n_clustering=5, num_clusters=1] Cluster sizes: [109]\n",
      "[n_clustering=5, num_clusters=2] Cluster sizes: [91, 18]\n",
      "[n_clustering=5, num_clusters=3] Cluster sizes: [88, 15, 6]\n",
      "[n_clustering=5, num_clusters=4] Cluster sizes: [69, 28, 8, 4]\n",
      "[n_clustering=5, num_clusters=5] Cluster sizes: [68, 28, 7, 4, 2]\n",
      "[n_clustering=5, num_clusters=6] Cluster sizes: [60, 29, 8, 7, 3, 2]\n",
      "[n_clustering=5, num_clusters=7] Cluster sizes: [57, 18, 14, 8, 7, 3, 2]\n",
      "[n_clustering=5, num_clusters=8] Cluster sizes: [50, 20, 19, 6, 5, 4, 3, 2]\n",
      "[n_clustering=5, num_clusters=9] Cluster sizes: [46, 22, 18, 6, 5, 4, 3, 3, 2]\n",
      "[n_clustering=5, num_clusters=10] Cluster sizes: [56, 17, 16, 7, 4, 3, 2, 2, 1, 1]\n",
      "[n_clustering=5, num_clusters=11] Cluster sizes: [50, 16, 14, 8, 4, 3, 3, 3, 3, 3, 2]\n",
      "[n_clustering=5, num_clusters=12] Cluster sizes: [33, 25, 16, 15, 4, 4, 3, 3, 2, 2, 1, 1]\n",
      "[n_clustering=7, num_clusters=1] Cluster sizes: [109]\n",
      "[n_clustering=7, num_clusters=2] Cluster sizes: [97, 12]\n",
      "[n_clustering=7, num_clusters=3] Cluster sizes: [93, 14, 2]\n",
      "[n_clustering=7, num_clusters=4] Cluster sizes: [70, 27, 11, 1]\n",
      "[n_clustering=7, num_clusters=5] Cluster sizes: [70, 27, 8, 3, 1]\n",
      "[n_clustering=7, num_clusters=6] Cluster sizes: [69, 25, 9, 3, 2, 1]\n",
      "[n_clustering=7, num_clusters=7] Cluster sizes: [67, 22, 8, 6, 3, 2, 1]\n",
      "[n_clustering=7, num_clusters=8] Cluster sizes: [67, 22, 8, 4, 3, 3, 1, 1]\n",
      "[n_clustering=7, num_clusters=9] Cluster sizes: [42, 27, 20, 8, 4, 3, 3, 1, 1]\n",
      "[n_clustering=7, num_clusters=10] Cluster sizes: [42, 27, 21, 7, 3, 3, 3, 1, 1, 1]\n",
      "[n_clustering=7, num_clusters=11] Cluster sizes: [45, 25, 20, 7, 3, 3, 2, 1, 1, 1, 1]\n",
      "[n_clustering=7, num_clusters=12] Cluster sizes: [42, 27, 19, 6, 3, 3, 3, 2, 1, 1, 1, 1]\n",
      "[n_clustering=9, num_clusters=1] Cluster sizes: [109]\n",
      "[n_clustering=9, num_clusters=2] Cluster sizes: [92, 17]\n",
      "[n_clustering=9, num_clusters=3] Cluster sizes: [92, 16, 1]\n",
      "[n_clustering=9, num_clusters=4] Cluster sizes: [88, 17, 3, 1]\n",
      "[n_clustering=9, num_clusters=5] Cluster sizes: [85, 11, 9, 3, 1]\n",
      "[n_clustering=9, num_clusters=6] Cluster sizes: [59, 29, 9, 8, 3, 1]\n",
      "[n_clustering=9, num_clusters=7] Cluster sizes: [58, 29, 9, 6, 3, 3, 1]\n",
      "[n_clustering=9, num_clusters=8] Cluster sizes: [58, 29, 9, 5, 3, 2, 2, 1]\n",
      "[n_clustering=9, num_clusters=9] Cluster sizes: [53, 32, 7, 5, 4, 3, 2, 2, 1]\n",
      "[n_clustering=9, num_clusters=10] Cluster sizes: [58, 29, 5, 5, 4, 3, 2, 1, 1, 1]\n",
      "[n_clustering=9, num_clusters=11] Cluster sizes: [53, 28, 7, 5, 4, 4, 3, 2, 1, 1, 1]\n",
      "[n_clustering=9, num_clusters=12] Cluster sizes: [53, 29, 6, 4, 4, 4, 3, 2, 1, 1, 1, 1]\n",
      "====== score_function=APS ======\n",
      "Computing conformal score...\n",
      "Splitting data...\n",
      "[n_clustering=3, num_clusters=1] Cluster sizes: [109]\n",
      "[n_clustering=3, num_clusters=2] Cluster sizes: [63, 46]\n",
      "[n_clustering=3, num_clusters=3] Cluster sizes: [44, 37, 28]\n",
      "[n_clustering=3, num_clusters=4] Cluster sizes: [32, 27, 26, 24]\n",
      "[n_clustering=3, num_clusters=5] Cluster sizes: [29, 25, 23, 18, 14]\n",
      "[n_clustering=3, num_clusters=6] Cluster sizes: [26, 25, 18, 17, 12, 11]\n",
      "[n_clustering=3, num_clusters=7] Cluster sizes: [22, 19, 17, 16, 14, 12, 9]\n",
      "[n_clustering=3, num_clusters=8] Cluster sizes: [19, 19, 18, 16, 12, 12, 7, 6]\n",
      "[n_clustering=3, num_clusters=9] Cluster sizes: [19, 18, 16, 14, 12, 11, 7, 7, 5]\n",
      "[n_clustering=3, num_clusters=10] Cluster sizes: [20, 17, 12, 11, 10, 9, 9, 9, 7, 5]\n",
      "[n_clustering=3, num_clusters=11] Cluster sizes: [19, 12, 12, 11, 11, 9, 9, 8, 7, 6, 5]\n",
      "[n_clustering=3, num_clusters=12] Cluster sizes: [17, 13, 13, 13, 9, 9, 7, 7, 6, 5, 5, 5]\n",
      "[n_clustering=5, num_clusters=1] Cluster sizes: [109]\n",
      "[n_clustering=5, num_clusters=2] Cluster sizes: [66, 43]\n",
      "[n_clustering=5, num_clusters=3] Cluster sizes: [39, 37, 33]\n",
      "[n_clustering=5, num_clusters=4] Cluster sizes: [35, 34, 29, 11]\n",
      "[n_clustering=5, num_clusters=5] Cluster sizes: [29, 25, 23, 21, 11]\n",
      "[n_clustering=5, num_clusters=6] Cluster sizes: [28, 22, 21, 14, 13, 11]\n",
      "[n_clustering=5, num_clusters=7] Cluster sizes: [20, 20, 19, 19, 11, 11, 9]\n",
      "[n_clustering=5, num_clusters=8] Cluster sizes: [20, 16, 15, 13, 13, 11, 11, 10]\n",
      "[n_clustering=5, num_clusters=9] Cluster sizes: [20, 19, 15, 12, 12, 11, 10, 5, 5]\n",
      "[n_clustering=5, num_clusters=10] Cluster sizes: [20, 15, 13, 13, 12, 11, 9, 7, 5, 4]\n",
      "[n_clustering=5, num_clusters=11] Cluster sizes: [16, 12, 12, 11, 11, 11, 9, 9, 8, 6, 4]\n",
      "[n_clustering=5, num_clusters=12] Cluster sizes: [14, 13, 12, 11, 11, 9, 8, 8, 7, 7, 5, 4]\n",
      "[n_clustering=7, num_clusters=1] Cluster sizes: [109]\n",
      "[n_clustering=7, num_clusters=2] Cluster sizes: [55, 54]\n",
      "[n_clustering=7, num_clusters=3] Cluster sizes: [44, 40, 25]\n",
      "[n_clustering=7, num_clusters=4] Cluster sizes: [36, 35, 22, 16]\n",
      "[n_clustering=7, num_clusters=5] Cluster sizes: [31, 30, 20, 15, 13]\n",
      "[n_clustering=7, num_clusters=6] Cluster sizes: [34, 20, 16, 16, 15, 8]\n",
      "[n_clustering=7, num_clusters=7] Cluster sizes: [20, 20, 17, 17, 15, 12, 8]\n",
      "[n_clustering=7, num_clusters=8] Cluster sizes: [20, 20, 15, 14, 11, 11, 10, 8]\n",
      "[n_clustering=7, num_clusters=9] Cluster sizes: [18, 15, 14, 13, 13, 11, 10, 8, 7]\n",
      "[n_clustering=7, num_clusters=10] Cluster sizes: [21, 17, 12, 12, 11, 11, 9, 7, 5, 4]\n",
      "[n_clustering=7, num_clusters=11] Cluster sizes: [16, 15, 13, 11, 11, 11, 7, 7, 6, 6, 6]\n",
      "[n_clustering=7, num_clusters=12] Cluster sizes: [14, 14, 12, 9, 9, 9, 9, 8, 8, 7, 6, 4]\n",
      "[n_clustering=9, num_clusters=1] Cluster sizes: [109]\n",
      "[n_clustering=9, num_clusters=2] Cluster sizes: [63, 46]\n",
      "[n_clustering=9, num_clusters=3] Cluster sizes: [43, 39, 27]\n",
      "[n_clustering=9, num_clusters=4] Cluster sizes: [36, 25, 25, 23]\n",
      "[n_clustering=9, num_clusters=5] Cluster sizes: [30, 23, 23, 18, 15]\n",
      "[n_clustering=9, num_clusters=6] Cluster sizes: [28, 22, 17, 15, 14, 13]\n",
      "[n_clustering=9, num_clusters=7] Cluster sizes: [24, 20, 16, 13, 13, 13, 10]\n",
      "[n_clustering=9, num_clusters=8] Cluster sizes: [23, 18, 15, 14, 11, 11, 10, 7]\n",
      "[n_clustering=9, num_clusters=9] Cluster sizes: [20, 16, 13, 12, 11, 11, 11, 10, 5]\n",
      "[n_clustering=9, num_clusters=10] Cluster sizes: [19, 18, 11, 11, 10, 10, 10, 9, 7, 4]\n",
      "[n_clustering=9, num_clusters=11] Cluster sizes: [19, 15, 14, 11, 11, 10, 8, 6, 6, 5, 4]\n",
      "[n_clustering=9, num_clusters=12] Cluster sizes: [14, 14, 13, 11, 11, 10, 8, 8, 6, 5, 5, 4]\n"
     ]
    }
   ],
   "source": [
    "# # for score_function in ['softmax', 'APS', 'RAPS']:\n",
    "# n_clustering_list = (np.array([.3, .5, .7, .9]) * n_totalcal).astype(np.int32)\n",
    "\n",
    "\n",
    "# for score_function in ['softmax', 'APS']:\n",
    "    \n",
    "#     print(f'====== score_function={score_function} ======')\n",
    "    \n",
    "#     print('Computing conformal score...')\n",
    "#     if score_function == 'softmax':\n",
    "#         scores_all = 1 - softmax_scores\n",
    "#     elif score_function == 'APS':\n",
    "#         scores_all = get_APS_scores_all(softmax_scores, randomize=True)\n",
    "#     elif score_function == 'RAPS': \n",
    "        \n",
    "#         # RAPS hyperparameters (currently using ImageNet defaults)\n",
    "#         lmbda = .01 \n",
    "#         kreg = 5\n",
    "        \n",
    "#         scores_all = get_RAPS_scores_all(softmax_scores, lmbda, kreg, randomize=True)\n",
    "#     else:\n",
    "#         raise Exception('Undefined score function')\n",
    "\n",
    "\n",
    "#     print('Splitting data...')\n",
    "#     # Split into clustering+calibration data and validation data\n",
    "#     totalcal_scores_all, totalcal_labels, val_scores_all, val_labels = split_X_and_y(scores_all, labels, n_totalcal, num_classes=num_classes, seed=0)\n",
    "\n",
    "#     for n_clustering in n_clustering_list:\n",
    "            \n",
    "#         # 0) Split data \n",
    "#         scores1_all, labels1, scores2_all, labels2 = split_X_and_y(totalcal_scores_all, \n",
    "#                                                            totalcal_labels, \n",
    "#                                                            n_clustering, \n",
    "#                                                            num_classes=num_classes, \n",
    "#                                                            seed=0)\n",
    "\n",
    "#         # 1) Compute embedding for each class\n",
    "#         embeddings = embed_all_classes(scores1_all, labels1, q=[0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "\n",
    "#         # 2) Do k-means with different k's\n",
    "#         for num_clusters in np.arange(1,13):\n",
    "#             kmeans = KMeans(n_clusters=num_clusters, random_state=0, n_init=10).fit(embeddings)\n",
    "#             cluster_assignments = kmeans.labels_  \n",
    "\n",
    "#             # Print cluster sizes\n",
    "#             print(f'[n_clustering={n_clustering}, num_clusters={num_clusters}] Cluster sizes:', [x[1] for x in Counter(cluster_assignments).most_common()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4953def0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== score_function=softmax ======\n",
      "Computing conformal score...\n",
      "Splitting data...\n",
      "Best n_clustering: 5\n",
      "Best num_clusters: 3\n",
      "Cluster sizes: [88, 15, 6]\n",
      "[Clustered conformal] Class coverage gap: 3.131593054758153\n",
      "[Clustered conformal] Set size metrics {'mean': 38.618291323892166, '[.25, .5, .75, .9] quantiles': array([30., 41., 49., 55.])}\n",
      "====== score_function=APS ======\n",
      "Computing conformal score...\n",
      "Splitting data...\n",
      "Best n_clustering: 9\n",
      "Best num_clusters: 5\n",
      "Cluster sizes: [30, 23, 23, 18, 15]\n",
      "[Clustered conformal] Class coverage gap: 6.701743518999062\n",
      "[Clustered conformal] Set size metrics {'mean': 66.72654921553159, '[.25, .5, .75, .9] quantiles': array([62., 71., 76., 80.])}\n"
     ]
    }
   ],
   "source": [
    "# for score_function in ['softmax', 'APS', 'RAPS']:\n",
    "for score_function in ['softmax', 'APS']:\n",
    "    \n",
    "    print(f'====== score_function={score_function} ======')\n",
    "    \n",
    "    print('Computing conformal score...')\n",
    "    if score_function == 'softmax':\n",
    "        scores_all = 1 - softmax_scores\n",
    "    elif score_function == 'APS':\n",
    "        scores_all = get_APS_scores_all(softmax_scores, randomize=True)\n",
    "    elif score_function == 'RAPS': \n",
    "        \n",
    "        # RAPS hyperparameters (currently using ImageNet defaults)\n",
    "        lmbda = .01 \n",
    "        kreg = 5\n",
    "        \n",
    "        scores_all = get_RAPS_scores_all(softmax_scores, lmbda, kreg, randomize=True)\n",
    "    else:\n",
    "        raise Exception('Undefined score function')\n",
    "\n",
    "\n",
    "    print('Splitting data...')\n",
    "    # Split into clustering+calibration data and validation data\n",
    "    totalcal_scores_all, totalcal_labels, val_scores_all, val_labels = split_X_and_y(scores_all, labels, n_totalcal, num_classes=num_classes, seed=0)\n",
    "\n",
    "\n",
    "    qhats, preds, class_cov_gap, set_size_metrics = clustered_conformal(totalcal_scores_all, totalcal_labels,\n",
    "                                                                        alpha,\n",
    "                                                                        tune_parameters=True,\n",
    "                                                                        n_clustering=None, num_clusters=None,\n",
    "                                                                        val_scores=val_scores_all, val_labels=val_labels)\n",
    "    print('[Clustered conformal] Class coverage gap:', class_cov_gap)\n",
    "    print('[Clustered conformal] Set size metrics', set_size_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096f1204",
   "metadata": {},
   "source": [
    "# Test ad-hoc heuristic\n",
    "\n",
    "For n_totalcal=10, num_classes=108 our heuristic says 5 points for clustering, 3 clusters.\n",
    "\n",
    "\n",
    "\n",
    "This is a hard task since we only have 1,080 total calibration points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "387bd90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clustering = 5\n",
    "num_clusters = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81379a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== score_function=softmax ======\n",
      "Computing conformal score...\n",
      "Splitting data...\n",
      "Cluster sizes: [81, 19, 7, 1, 1]\n",
      "[Clustered conformal] Class coverage gap: 2.1080014658611397\n",
      "[Clustered conformal] Set size metrics {'mean': 37.021779144955744, '[.25, .5, .75, .9] quantiles': array([29., 40., 47., 53.])}\n",
      "====== score_function=APS ======\n",
      "Computing conformal score...\n",
      "Splitting data...\n",
      "Cluster sizes: [29, 27, 27, 20, 6]\n",
      "[Clustered conformal] Class coverage gap: 2.602582134356466\n",
      "[Clustered conformal] Set size metrics {'mean': 39.76418858685417, '[.25, .5, .75, .9] quantiles': array([32., 43., 51., 56.])}\n"
     ]
    }
   ],
   "source": [
    "# for score_function in ['softmax', 'APS', 'RAPS']:\n",
    "for score_function in ['softmax', 'APS']:\n",
    "    \n",
    "    print(f'====== score_function={score_function} ======')\n",
    "    \n",
    "    print('Computing conformal score...')\n",
    "    if score_function == 'softmax':\n",
    "        scores_all = 1 - softmax_scores\n",
    "    elif score_function == 'APS':\n",
    "        scores_all = get_APS_scores_all(softmax_scores, randomize=True)\n",
    "    elif score_function == 'RAPS': \n",
    "        \n",
    "        # RAPS hyperparameters (currently using ImageNet defaults)\n",
    "        lmbda = .01 \n",
    "        kreg = 5\n",
    "        \n",
    "        scores_all = get_RAPS_scores_all(softmax_scores, lmbda, kreg, randomize=True)\n",
    "    else:\n",
    "        raise Exception('Undefined score function')\n",
    "\n",
    "\n",
    "    print('Splitting data...')\n",
    "    # Split into clustering+calibration data and validation data\n",
    "    totalcal_scores_all, totalcal_labels, val_scores_all, val_labels = split_X_and_y(scores_all, labels, n_totalcal, num_classes=num_classes, seed=0)\n",
    "\n",
    "\n",
    "    qhats, preds, class_cov_gap, set_size_metrics = _clustered_conformal(totalcal_scores_all, totalcal_labels,\n",
    "                                                                        alpha,\n",
    "                                                                        n_clustering=n_clustering, num_clusters=num_clusters,\n",
    "                                                                        val_scores=val_scores_all, val_labels=val_labels)\n",
    "    print('[Clustered conformal] Class coverage gap:', class_cov_gap)\n",
    "    print('[Clustered conformal] Set size metrics', set_size_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fcd4d923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.cache/enron_n=10/softmax/seed=0_allmetrics.pkl',\n",
       " '.cache/enron_n=10/softmax/seed=1_allmetrics.pkl',\n",
       " '.cache/enron_n=10/softmax/seed=2_allmetrics.pkl',\n",
       " '.cache/enron_n=10/softmax/seed=3_allmetrics.pkl',\n",
       " '.cache/enron_n=10/softmax/seed=4_allmetrics.pkl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scratch\n",
    "\n",
    "import glob\n",
    "\n",
    "file_names = sorted(glob.glob('.cache/enron_n=10/softmax/*.pkl'))\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca6d9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
